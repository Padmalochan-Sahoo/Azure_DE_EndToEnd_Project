

## Create a resource group
az group create --name streamanalyticsrg --location eastus

## Prepare the input data

Set the SKU to F1 to use the free tier if it's available with your subscription. If not, choose the next lowest tier.

1 - iotHubName=MyASAIoTHub
az iot hub create --name $iotHubName --resource-group streamanalyticsrg --sku S1

Once the IoT hub has been created, get the IoT Hub connection string using the az iot hub connection-string show command. Copy the entire connection string and save it. You use it while adding the IoT Hub as an input to your Stream Analytics job.

az iot hub connection-string show --hub-name $iotHubName

2 - Add a device to IoT Hub using the az iothub device-identity create command. This example creates a device called MyASAIoTDevice.

az iot hub device-identity create --hub-name $iotHubName --device-id "MyASAIoTDevice"

3 - Get the device connection string using the az iot hub device-identity connection-string show command. Copy the entire connection string and save it for when you create the Raspberry Pi simulator.

az iot hub device-identity connection-string show --hub-name $iotHubName --device-id "MyASAIoTDevice" --output table

Output example:
HostName=MyASAIoTHub.azure-devices.net;DeviceId=MyASAIoTDevice;SharedAccessKey=a2mnUsg52+NIgYudxYYUNXI67r0JmNubmfVafojG8=



### Create a Blob storage usning azure cli

1 - Create a general-purpose storage account with the az storage account create command. The general-purpose storage account can be used for all four services: blobs, files, tables, and queues.

storageAccountName="asatutorialstorage$RANDOM"
az storage account create --name $storageAccountName \ 
--resource-group streamanalyticsrg \
--location eastus --sku Standard_ZRS \
--encryption-services blob


2 - Get the key for your storage account by running the az storage account keys list command.

key=$(az storage account keys list -g streamanalyticsrg -n $storageAccountName --query "[0].value" -o tsv)
echo $key

Note down the access key for the Azure storage account. You will use this key later in this quickstart.

3 - Create a container named state for storing blobs with the az storage container create command. You use the storage account key to authorize the operation to create the container

az storage container create --account-name $storageAccountName --name state --account-key $key --auth-mode key


#### Create a Stream Analytics job

Create a Stream Analytics job with the az stream-analytics job create command.

az stream-analytics job create --job-name "streamanalyticsjob" \
--resource-group "streamanalyticsrg" --location "eastus" \
--output-error-policy "Drop" --out-of-order-policy "Drop" \
--order-max-delay 5 --arrival-max-delay 16 --data-locale "en-US"



##### Configure input to the job

Add an input to your job by using the az stream-analytics input cmdlet. This cmdlet takes the job name, job input name, resource group name, and the input properties in JSON format as parameters. In this example, you'll create an IoT Hub as an input.
Note - 
Replace IOT HUB ACCESS KEY with the value of Shared Access Key in the IOT Hub connection string you saved.
While replacing the value, make sure that you don't delete \ (escape) character for " (double quotes).
Update the value of iotHubNamespace in the following command if you used a name other than MyASAIoTHub. 
Run echo $iotHubName to see the name of your IoT Hub.


az stream-analytics input create --properties "{\"type\":\"Stream\",\"datasource\":{\"type\":\"Microsoft.Devices/IotHubs\",\"properties\":{\"consumerGroupName\":\"\$Default\",\"endpoint\":\"messages/events\",\"iotHubNamespace\":\"MyASAIoTHub\",\"sharedAccessPolicyKey\":\"IOT HUB ACCESS KEY\",\"sharedAccessPolicyName\":\"iothubowner\"}},\"serialization\":{\"type\":\"Json\",\"encoding\":\"UTF8\"}}" --input-name "asaiotinput" --job-name "streamanalyticsjob" --resource-group "streamanalyticsrg"



###### Configure output to the job

Add an output to your job by using the az stream-analytics output create cmdlet. This cmdlet takes the job name, job output name, resource group name, data source in JSON format, and serialization type as parameters.

Important

Replace STORAGEACCOUNTNAME> with the name of your Azure Storage account and STORAGEACCESSKEY> with the access key for your storage account. If you didn't note down these values, run the following commands to get them: echo $storageAccountName and echo $key. 

While replacing the values, make sure that you don't delete \ (escape) character for " (double quotes).


az stream-analytics output create --job-name streamanalyticsjob --datasource "{\"type\":\"Microsoft.Storage/Blob\",\"properties\":{\"container\":\"state\",\"dateFormat\":\"yyyy/MM/dd\",\"pathPattern\":\"{date}/{time}\",\"storageAccounts\":[{\"accountKey\":\"STORAGEACCESSKEY\",\"accountName\":\"STORAGEACCOUNTNAME\"}],\"timeFormat\":\"HH\"}}" --serialization "{\"type\":\"Json\",\"properties\":{\"format\":\"Array\",\"encoding\":\"UTF8\"}}" --output-name asabloboutput --resource-group streamanalyticsrg


#### Define the transformation query (optional)

az stream-analytics transformation create \
--resource-group streamanalyticsrg \
--job-name streamanalyticsjob \
--name Transformation --streaming-units "6" \
--saql "SELECT * INTO asabloboutput FROM asaiotinput WHERE Temperature > 27"



##### Start the Stream Analytics job and check the output


Start the job by using the az stream-analytics job start cmdlet. This cmdlet takes the job name, resource group name, output start mode, and start time as parameters. OutputStartMode accepts values of JobStartTime, CustomTime, or LastOutputEventTime.

After you run the following cmdlet, it returns True as output if the job starts.

az stream-analytics job start \
    --resource-group streamanalyticsrg \
    --name streamanalyticsjob \
    --output-start-mode JobStartTime

example - 
az stream-analytics job start --job-name 'project-stream-job' --resource-group "IOT_Resources" --output-start-mode "CustomTime" --output-start-time "2024-02-16T17:25:00Z"




#### Clean up resources

Delete the resource group, which will delete all the resources in the resource group including Stream Analytics job, IoT Hub, and Azure Storage account.

az group delete \
    --name streamanalyticsrg \
    --no-wait








Qucik_start - 

https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-quick-create-portal
https://learn.microsoft.com/en-us/azure/stream-analytics/quick-create-visual-studio-code
https://learn.microsoft.com/en-us/azure/stream-analytics/quick-create-azure-cli
https://learn.microsoft.com/en-us/azure/stream-analytics/quick-create-bicep?tabs=CLI
https://learn.microsoft.com/en-us/azure/stream-analytics/quick-create-azure-resource-manager
https://learn.microsoft.com/en-us/azure/stream-analytics/quick-create-terraform?tabs=azure-cli
https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-quick-create-powershell
